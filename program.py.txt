import tensorflow as tf
from tensorflow.keras import layers, models, Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
import shap
import lime
from lime import lime_image
from skimage.segmentation import mark_boundaries

# -------------------------
# 1. Data Loaders
# -------------------------
img_size = (224, 224)
batch_size = 32

train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    "dataset/train",
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary"
)

val_generator = val_datagen.flow_from_directory(
    "dataset/val",
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary"
)

test_generator = test_datagen.flow_from_directory(
    "dataset/test",
    target_size=img_size,
    batch_size=batch_size,
    class_mode="binary",
    shuffle=False
)

# -------------------------
# 2. Hybrid Model: Xception + Transformer + Capsule
# -------------------------
base_model = tf.keras.applications.Xception(
    weights="imagenet", include_top=False, input_shape=(224,224,3)
)
base_model.trainable = False

x = layers.Conv2D(64, (3,3), activation="relu", padding="same")(base_model.output)
x = layers.MaxPooling2D((2,2))(x)

# Transformer block
transformer_block = layers.MultiHeadAttention(num_heads=4, key_dim=64)
attn_output = transformer_block(x, x)
x = layers.Add()([x, attn_output])
x = layers.LayerNormalization()(x)

# Capsule network (simple implementation)
caps = layers.Conv2D(32, (3,3), activation="relu", padding="same")(x)
caps = layers.Reshape((-1, 32))(caps)
caps = layers.Dense(16, activation="relu")(caps)
caps_output = layers.Flatten()(caps)

output = layers.Dense(1, activation="sigmoid")(caps_output)

xtcnet = Model(base_model.input, output, name="XTCNet")
xtcnet.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
xtcnet.summary()

# -------------------------
# 3. Training
# -------------------------
history = xtcnet.fit(
    train_generator,
    epochs=10,
    validation_data=val_generator
)

# -------------------------
# 4. Explainability Functions
# -------------------------

# Grad-CAM
def grad_cam(model, img, layer_name):
    grad_model = Model([model.inputs], [model.get_layer(layer_name).output, model.output])
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img)
        loss = predictions[:, 0]

    grads = tape.gradient(loss, conv_outputs)[0]
    weights = tf.reduce_mean(grads, axis=(0,1))
    cam = np.zeros(conv_outputs[0].shape[0:2], dtype=np.float32)

    for i, w in enumerate(weights):
        cam += w * conv_outputs[0][:,:,i]

    cam = np.maximum(cam, 0)
    cam = cam / np.max(cam)
    return cam

# SHAP
def shap_explanation(model, sample):
    explainer = shap.GradientExplainer(model, sample)
    shap_values = explainer.shap_values(sample)
    shap.image_plot(shap_values, sample)

# LIME
def lime_explanation(model, img):
    def predict_fn(images):
        images = np.array(images).astype(np.float32)
        return model.predict(images)
   
    explainer = lime_image.LimeImageExplainer()
    explanation = explainer.explain_instance(
        img[0].astype("double"),
        predict_fn,
        top_labels=1,
        hide_color=0,
        num_samples=1000
    )
    temp, mask = explanation.get_image_and_mask(
        explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False
    )
    plt.imshow(mark_boundaries(temp / 255.0, mask))
    plt.axis("off")
    plt.show()

# -------------------------
# 5. Example on One Image
# -------------------------
sample_img, _ = test_generator.next()
sample_img = sample_img[0:1]

# Grad-CAM after Xception
cam_xception = grad_cam(xtcnet, sample_img, "block14_sepconv2_act")
plt.imshow(sample_img[0])
plt.imshow(cam_xception, cmap="jet", alpha=0.5)
plt.title("Grad-CAM after Xception")
plt.show()

# Grad-CAM after Transformer
cam_transformer = grad_cam(xtcnet, sample_img, transformer_block.name)
plt.imshow(sample_img[0])
plt.imshow(cam_transformer, cmap="jet", alpha=0.5)
plt.title("Grad-CAM after Transformer")
plt.show()

# Grad-CAM after Capsule
cam_capsule = grad_cam(xtcnet, sample_img, "conv2d_1")  # last conv before capsule
plt.imshow(sample_img[0])
plt.imshow(cam_capsule, cmap="jet", alpha=0.5)
plt.title("Grad-CAM after Capsule")
plt.show()

# SHAP
shap_explanation(xtcnet, sample_img)

# LIME
lime_explanation(xtcnet, sample_img)